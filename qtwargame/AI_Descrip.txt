MaxAttackRange = const c #s.t. c^2*boardsize is reasonable (<20,000,000 or so perferably)

prob_add(x,y) = x + y - (x * y)

prob_sum_of [] = 0
	| L = prob_add(hd(L),prob_sum_of(tl(L)))

Val(T,M,P) = (if IsBuilding(T)
			 then Cost(T)
			 else (Cost(T) + FutureMoveVal(T,M,P))
			 ) / T.hitpoints() #todo: try different ways to make value dependent on how much it has already been killed

ChanceSomethingThere(P,M) = prob_sum_of(MoveProb(T,M,P) for T in AllTroops)

#WinChance is a huristic that estimates the sort of ability of one troop to destroy another and vice versa.
#it is almost certainly redundant with the entire value/probability system.
AttackTroopPointProb(AT,DT,M,AP,DP) = MoveProb(DT,M,DP) # * WinChance(AT,DT)

#this represents the best attack of a single troop against the many targets it has.
#it does not represent the optimal attack senario including all attacking units, I belive this too slow of a problem.
all_attacks_prob(M) := ((DT,Point)->Prob)

#represents best attack from a single point against its many targets


TroopAttackValGather(AT,M,AP) := ((DT,DP)->prob)

    tpvals = [ValInfo<Val(DT,M,DP), AttackTroopPointProb(AT,DT,M,AP,DP)>
                for DT in EnemyTroops
                    for DP in square_range(AP,AT.range) exclude AP]
    tpvals = sort(tpvals,greatest_in_front)

    tprobs := (Troop->Prob)
    attacks := ((DT,DP)->prob)

    tot_prob = 0
    for (val,prob_base,troop,TP) in tpvals:
        attprob = prob_base * (1 - tot_prob)
        tot_prob += attprob
        attacks[troop,TP] = attprob
        MoveProb(M,troop,TP) -= attprob * MoveProb(M,AT,AP)#order does matter, so make sure to calculae this in same order as turns, move, attack, next player's move, attack, etc...

        all_attacks_prob(M)[troop,TP] (prob)+= attprob

    return attack

AttackVal(AT,M,AP) = sum_of(Val(DT,M,DP) * TroopAttackValGather(AT,M,AP)[DT,DP] for DT in EnemyTroops for DP in square_range(AP,AT.range) exclude AP)

NetValModifier(T,M,P) = (AttackVal(T,M,P) - Val(T,M,P) * all_attacks_prob(M)[T,P]) * (1 - ChanceSomethingThere(P,M))#todo:ChanceSomethingThere really needs to be ChanceSomethingElseThere

#accumulates the value of moving to locations along optimal path from origin
MoveToVal(T,0,P) = NetValModifier(T,0,P)
        | MoveToVal(T,M,P) =
                        NetValModifier(T,M,P) +
                                max_of(
                                        MoveToVal(T,M-1,P)
                                        for P in square_range(P,1)
                                )

#represents the total value of the optimal path of the troop both forwards and backwards in time assuming being on a point at move M
MovePathVal(T,MaxM,P) = MoveToVal(T,MaxM,P)
	| MovePathVal(T,M,P) =
		(max_of( MovePathVal(T,M+1,P), P)
				for P in square_range(P,1))
			- (MoveToVal(T,M+1,P) - NetValModifier(T,M+1,P)) #the value of the best child move of M+1 (>= MoveToVal(T,M,P))
			+ MoveToVal(T,M,P)

#represents the accumulated value of the move path ahead of it
FutureMoveVal(T,M,P) = MovePathVal(T,M,P) + NetValModifier(T,M,P) - MoveToVal(T,M,P)

LandVal(Play) = #look at how landVal is calculated in the code

ValModfier(V) = V #todo:consider making this non-liniar

#requirements for moveprob
# 1. sumof(MoveProb(T,M,P) for T in AllTroops) <= 1.0
# 2. sumof(MoveProb(T,M,P) for P in Board) <= T.NumOfSquaresOccupied
# 3. MoveProb deteriorates with attacks according to the probabilies of them happening

/*
Basic idea how moveprob works:

Takes the value from the previous iteration, and uses it as a guide on making a set of probailities of future move points that is consistent with basic movement rules.
It uses the values by
*/

#current status 1/3
MoveProb(T,M,P) = ValModfier(MovePathVal_Prev(T,M,P)) / sum_of(ValModfier(MovePathVal_Prev(T,M,MP)) for MP in AllSqares)






#once this gets worked out better, 3/3
#current status 0/3

CalcMoveProbs(0) =
    MoveProb(T) := (Point->Prob)
        probs :=  (Point->(Prob default 0))
        probs[T.P] = 1.0
        return probs

CalcMoveProbs(M) :=
    TotMoveProb := (Point->(Prob default 0))

    MoveProb(T) := (Point->Prob)
        probs :=  (Point->(Prob default 0))
        prevps = MoveProb(T,M-1)
        for BP in Board:
            already_taken_total = sum_of(TotMoveProb[P] for P in SquareIter(BP,T.movmementrange))
            base_move_possibilties = sum_of(1 for P in SquareIter(BP,T.movmementrange))

            for PP in SquareIter(BP,T.movmementrange):
                #not enough probabilty to maintain itself
                if(base_move_possibilties - already_taken_total < move_prev_prob[P]):
                    #takes all the probaility left, if this ever happens, then it kind of skrews things up
                    #because it is as if it were attacked.
                    prob = 1.0 - TotMoveProb[PP]
                else:
                stable_val_modifier = ValModfier(MovePathVal(T,M,BP)) / sum_of(ValModfier(MovePathVal(T,M,MP)) for MP in SquareIter(BP,1));
                for PP in SquareIter(BP,1):
                    probs[PP] += prevps[BP] * stable_val_modifier

        return probs

    # sequencial algorithm, troop ordering matters, but there is currently
    # no ordering mechanism to optimize this process, so it is randomized to reduce impact
    for T in random_order(AllTroops):
        MoveProb(T)

main_calc():

#Micro Move

val_attack(0,T,MP,AP) > 0 #todo:list the actual initial value here
	| val_attack(I,T,MP,AP) = val_attack(I-1,T,MP,AP) - val_attack(I-1,T,MP,AP) *
		sum(
			sum(val_adj(I-1,AT,AMP,AP) for AMP in AT.movebox)
			for AT in EnemyTroops
		)

val_move(T,P)
val_tot(T,MP) = val_move(T,MP) + sum(val_attack(T,P))
adjval_m(T,M)
adjval_a(T,M,A)
